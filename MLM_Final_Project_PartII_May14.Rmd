---
title: "MLM Final Project Part 2ab"
date:  "`r format(Sys.time(), '%B %d %Y')`"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
# read in data
library(tidyverse)
dat <- read_csv("dataset/classroom.csv")
# create math1st
dat <- dat %>% mutate(math1st=mathkind+mathgain)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
###Load libraries
if(!requireNamespace("here"))
  install.packages("here", repos = "https://cloud.r-project.org")
require("here")

if(!requireNamespace("ggplot2"))
  install.packages("ggplot2", repos = "https://cloud.r-project.org")
require("ggplot2")

if(!requireNamespace("lme4"))
  install.packages("lme4", repos = "https://cloud.r-project.org")
require("lme4")

if(!requireNamespace("lmerTest"))
  install.packages("lmerTest", repos = "https://cloud.r-project.org")
require("lmerTest")

if(!requireNamespace("car"))
  install.packages("car", repos = "https://cloud.r-project.org")
require("car")

if(!requireNamespace("dplyr"))
  install.packages("dplyr", repos = "https://cloud.r-project.org")
require("dplyr")
```

## Team Members and division of work: 
Beverlin del Rosario(scripter), Jinal Shah(analyst), John Zhang(scripter), Wooyong Jung(coder), Yingtian Liang(coder)

## Question 1
Refit the model in Part 1 that has all fixed effects as well as random intercepts (in schools and classrooms). Recall that `math1st = mathkind + mathgain` is the outcome. The model is `math1st ~ housepov + yearstea + mathprep + mathknow + ses + sex + minority + (1|schoolid/classid), REML = T)`

```{r}
# Insert code to fit model and print summary 
fit1 <- lmer(math1st ~ housepov + yearstea + mathprep + mathknow + ses 
             + sex + minority + (1|schoolid/classid), REML=T, data=dat)
summary(fit1)
```

a. Construct the residual that removes only the 'fixed effects' then subtract it from the outcome; call this residual resFE
    i. R hint 1: `predict` has an option to generate the prediction based on the fixed effects only. 
    ii. R hint 2: If you decide to add a solumn to your data frame with resFE, note that predict only generates predictions for cases uses in the model *after listwise deletion.* 

```{r}
# Insert code here to construct residual 
resFE <- dat$math1st[complete.cases(dat)]-predict(fit1,re.form=~0)
dat$resFE[complete.cases(dat)] <- resFE
```

## Question 2 
Show that the residual is not indepedent within schools in some manner. 
```{r}
# Insert code to show that the residual, resFE, is not indepedent within school
ggplot(dat[complete.cases(dat),],aes(reorder(schoolid,resFE,FUN=median),resFE))+
  geom_boxplot()
```
If the errors were independent, the medians would be much closer to zero for every school.


## Question 3
### a. Construct the residual that utilizes the BLUPs for the random effects using the R command `residuals`.
    
    i. Call the new residual resFE_RE
    
```{r}
# Insert code to construct the residual 
resFE_RE <- residuals(fit1)
dat$resFE_RE[complete.cases(dat)] <- resFE_RE
```

## Question 4
### a. Show that these new residuals, resFE_RE are MUCH LESS (if not completely un-) correlated within schools, using the same method as before (boxplot?)
```{r}
# Insert code to show that new residuals, resFE_RE, is much less correlated within schools
ggplot(dat[complete.cases(dat),],aes(reorder(schoolid,resFE_RE,FUN=median),resFE_RE))+
  geom_boxplot()
```

## Question 5
### a. Generate the two sets of BLUPs (for random effects zeta0 and eta0)
```{r}
# Insert code to generate the two sets of BLUPS (zeta0 and eta0)
ranefs1 <- ranef(fit1)
zeta0M1 <- ranefs1$schoolid[,1]
eta0M1 <- ranefs1$classid[,1]
```

### b. Examine these for normality (include evidence), and comment.
```{r}
# Insert code to examine BLUPs for normality
par(mfrow=c(1,2))
plot(density(zeta0M1))
qqnorm(zeta0M1)
qqline(zeta0M1)
```
```{r}
# Insert code to examine BLUPs for normality
par(mfrow=c(1,2))
plot(density(eta0M1))
qqnorm(eta0M1)
qqline(eta0M1)
```

  Response: It seems the BLUPs for school effects are mostly normal by looking at the Q-Q plot. Though the Q-Q  plot shows some concern with both tails. They are possibly skewed to the right. 

## Question 6 
### a. Fit a slightly more complicated model with the same fixed effects, but now add a random slope for minority, correlated wtih the random intercept, at the school level (keep the classroom level random intercept).
```{r}
# Insert code to fit the slightly more complicated model and print the summary
fit2 <- lmer(math1st ~ housepov + yearstea + mathprep + mathknow + ses 
             + sex + minority + (1|classid) + (minority|schoolid), REML=T, data=dat)
summary(fit2)
```

### b. Construct the residual (individual, level 1) and the BLUPs for the remaining random effects. Call the new residual resFE_RE as before.
```{r}
# Insert code to construct residual and BLUPs 
resFE_RE2 <- residuals(fit2)
```

### c. Examine all error estimates (individual level residuals, BLUPs (school and classroom level) for normality (and comment)). 
```{r}
# Insert code to examine error estimates.
ranefs2 <- ranef(fit2) # BLUPS
zeta0M2 <- ranefs2$schoolid[,1] # school random intercept
zeta1M2 <- ranefs2$schoolid[,2] # school random slope for minority
eta0M2 <- ranefs2$classid[,1] # class random intercept

# normality
par(mfrow=c(1,2))
plot(density(resFE_RE2))
qqnorm(resFE_RE2)
qqline(resFE_RE2)

par(mfrow=c(1,2))
plot(density(zeta0M2))
qqnorm(zeta0M2)
qqline(zeta0M2)

par(mfrow=c(1,2))
plot(density(zeta1M2))
qqnorm(zeta1M2)
qqline(zeta1M2)

par(mfrow=c(1,2))
plot(density(eta0M2))
qqnorm(eta0M2)
qqline(eta0M2)
```

  Response: The individual level residuals look normal except on both tails. The BLUPs for the school level random effect shows some concern with the normality assumption. The points on the both tails on the Q-Q plot lies outside of the Q-Q line. However, the BLUPs for the random effect of minorities at school level looks highly non-normal. It has heavy left and right tails.


### d. Plot zeta0 vs. zeta1 to see whether the estimated correlation is consistent with the observed. Briefly comment. 
```{r}
# Insert code for plot and estimate correlation
df <- tibble(
  schoolid=as.integer(unique(dat$schoolid[complete.cases(dat)])),
  zeta0=zeta0M2,
  zeta1=zeta1M2
  )

# Plot zeta0 vs. zeta1 and estimate correlation
df %>% 
  ggplot(aes(x = zeta0, y = zeta1)) +
  geom_point() +
  theme_bw()

cor(zeta1M2,zeta0M2)
```

  Response: The estimated correlation is -0.79, and the observed is -0.83. The estimated one is consistent with the observed one.


### e. Track down those odd points in the scatterplot. What schools are they? Do they have anything in common? (You should comment)
```{r}
# Calculate mean value of minority for each school 
df.minority <- dat %>% 
  drop_na() %>% 
  group_by(schoolid) %>% 
  summarise(prop_minor = mean(minority))
  
# Merge the mean values of school minority to random effects data frame
df <- merge(df, df.minority, by = "schoolid", all.x = TRUE)

# Index school in which minority doesn't vary 
df <- df %>% 
  mutate(invariant_minority = ifelse(prop_minor %in% c(0, 1), 1, 0))

# Plot
df %>% 
  ggplot(aes(x = zeta0, y = zeta1, color = factor(invariant_minority))) +
  scale_color_manual(values = c("black", "red"), labels = c("Varying", "Invariant")) +
  geom_point() +
  labs(color = "Minority in each School") +
  theme_bw() +
  theme(legend.position = c(0.85, 0.87))

# Track down School ID marked with the red points in the plot
# Create separated plots for each minority = 1 and 0
library(ggrepel)
df2 <- df %>% 
  mutate(minority1 = ifelse(prop_minor == 1, 1, 0), minority0 = ifelse(prop_minor == 0, 1, 0))

# Minority = 1
df2 %>% 
  ggplot(aes(x = zeta0, y = zeta1, color = factor(minority1))) +
  scale_color_manual(values = c("black", "red"), labels = c("Varying", "Minority = 1")) +
  geom_point() +
  geom_text_repel(aes(label = schoolid), segment.size  = 0.2, segment.color = "grey50", 
                  nudge_x = .15, data = df2[df2$minority1 == 1,]) +
  labs(color = "Minority") +
  theme_bw() +
  theme(legend.position = c(0.77, 0.89)) -> plot_minority1

# Minority = 0
df2 %>% 
  ggplot(aes(x = zeta0, y = zeta1, color = factor(minority0))) +
  scale_color_manual(values = c("black", "red"), labels = c("Varying", "Minority = 0")) +
  geom_point() +
  geom_text_repel(aes(label = schoolid), segment.size  = 0.2, segment.color = "grey50", 
                  nudge_x = .15, data = df2[df2$minority0 == 1,]) +
  labs(color = "Minority") +
  theme_bw() +
  theme(legend.position = c(0.77, 0.89))  -> plot_minority0

gridExtra::grid.arrange(plot_minority1, plot_minority0, nrow = 1)
```
      Response: In the schools marked with red points in the scatter plots above, the values of student's minority don't vary at all (either 1 or 0).


## Question 7
Make a *person-period* file with math score (Kindergarten and First grade). That is, `math0 <- mathkind; math1 <- mathkind + mathgain` (you shave to make this work in the dataframe). Using `reshape` in R, you ahve to be careful to specify the name of the math variable (`math0` and `math1`) as *varying*. 

```{r}
# Insert code to create the variables math0 and math1 and to reshape data
dat_pp <- dat %>% mutate(math0=mathkind,math1=mathkind+mathgain) %>%
  reshape(varying=c("math0","math1"),v.names="math",
          timevar="year",times=c(0,1),direction="long")
```


## Question 8
We ignore classrooms in this analysis, but keep it in the notation. 

### a. Fit a model with `math` as outcome, and fixed effect for time trend (`year`), and random intercepts for schools.
```{r}
# Insert code to fit model and print summary
fit3 <- lmer(math~year+(1|schoolid),data=dat_pp)
summary(fit3)
```

### b. Write down the model

    Equation: 
$$
\begin{gathered}
MATH_{tijk}=b_0+\zeta_{0k}+b1TIME_{tijk}+\varepsilon_{tijk} \\
\text{with } \zeta_{0k}\sim N(0,\sigma^2_{\zeta_0}) \text{ and } \varepsilon_{tijk}\sim N(0,\sigma^2_{\varepsilon})
\text{, independent of each other,} \\
\text{and i, j, and k represent times, students, and schools, respectively.}
\end{gathered}
$$
    
### c. Add random intercepts for child
```{r}
# Insert code to fit new model and print summary output
fit4 <- lmer(math~year+(1|schoolid)+(1|childid),data=dat_pp)
summary(fit4)
```

### d. Write down the model

    Equation: 
$$
\begin{gathered}
MATH_{tijk}=b_0+\delta_{0ijk}+\zeta_{0k}+b_1TIME_{tijk}+\varepsilon_{tijk} \\
\text{with } \delta_{0ijk}\sim N(0,\sigma^2_{\delta_0}), \zeta_{0k}\sim N(0,\sigma^2_{\zeta_0}) \text{ and } \varepsilon_{tijk}\sim N(0,\sigma^2_{\varepsilon})
\text{, independent of each other,} \\
\text{and i, j, and k represent times, students, and schools, respectively.}
\end{gathered}
$$


## Question 9
Report original and new variance estimates of $\sigma^2_{\zeta_0}$ (between schools) and $\sigma^2_{\varepsilon}$ (within schools):

$\sigma^2_{\zeta_0}:$ 348.7, 307.5\newline
\newline
$\sigma^2_{\varepsilon}:$ 1268.4, 599.1 
    
### a. Compute a pseudo $R^2$ relating the between school variation and ignoring between students in the same school. In other words, what fraction of the between-school variance in the first model is 'explained' by the addition of a student random effect?
```{r}
# Insert code to compute psuedo R^2 or do this inline 
(348.7-307.5)/348.7
```

### b. Does the total variation stay about the same (adding between children within schools variance as well, to the second model results)?
    
    Response: Yes.
    
## Question 10 
Add a random slope ($\zeta_1$) for the trend (year) within schools (uncorrelated with random intercept ($\zeta_0$))
```{r}
# Insert code to fit model and print out summary 
fit5 <- lmer(math~year+(year||schoolid)+(1|childid),data=dat_pp)
summary(fit5)
```


### a. Generate the BLUPs for the random effects and examine whether the independence between zeta_0 and zeta_1 is reflected in a scatterplot of these two sets of effects.
```{r}
# Insert code to generate BLUPs
ranefs5 <- ranef(fit5)
zeta1M5 <- ranefs5$schoolid[,1]
zeta0M5 <- ranefs5$schoolid[,2]
plot(zeta1M5,zeta0M5,xlab="zeta1",ylab="zeta0")
cor(zeta1M5, zeta0M5)
```

  Response: The correlation is -0.11, and they are hardly correlated (i.e. independent).


### b. Compute V_S(year = 0) and V_S (year = 1). Since there are only two years, this is a form of heteroscedasticity in the random effects.
```{r}
# Insert code to compute terms or do this inline 
324.81 # V_S(year = 0)
324.81+1^2*88.67 # V_S (year = 1)
```

i. In which year is there more between school variation, net of all else?
    
    Response: First grade (year = 1).

## Question 11
If you ran the model BY YEAR, and removed the year trend from the model, would you get the same estimates for the variances between schools? 
```{r}
# Insert code to fit the two models by year and print out the summary 
## year = 0
fit6 <- lmer(math~(1|schoolid) ,data=dat_pp[dat_pp$year==0,])
summary(fit6)
## year = 1
fit7 <- lmer(math~(1|schoolid),data=dat_pp[dat_pp$year==1,])
summary(fit7)
```

  Response: When running the models separately, for the kindergarten(year=0) we get, $V_S = 364.3$ and for the first grade (year =1) we get $V_S = 306.8$. These variance estimates are not the same  compared to question 11 where we added a random slope for time trend (year) within schools. When we run the model separately, we get more between school variation for year 0 compared to year 1 which is opposite.ÃŸ 


## Question 12 
Rerun the last nested longitudinal model, allowing correlation between intercept and slope.

### a. Is the correlation significant?
```{r}
# Insert code to fit model, print the summary output, and compare models
fit8 <- lmer(math~year+(year|schoolid)+(1|childid),data=dat_pp)
summary(fit8)
ranefs8 <- ranef(fit8)
zeta0M8 <- ranefs8$schoolid[,1]
zeta1M8 <- ranefs8$schoolid[,2]
test <-cor.test(zeta0M8, zeta1M8)
test
anova(fit5, fit8, refit= F)

```

  Response: Yes, the correlation is significant. The p-value of the correlation test is less than 0.05.


### b. Compute V_S (year = 0) and V_S(year = 1) for this new model (your formula should include covariance terms).
```{r}
# Insert code to compute terms or do this inline 
370.6 # year=0
370.6+2*1*-0.45*19.25*10.44+1^2*109.1
```

  i. Is this result (and thus model) more consistent with the separate grade analysis? You are implicitly testing model fit here. 
      
      Response: Yes, V_S(year=1) is smaller than V_S(year=0).
